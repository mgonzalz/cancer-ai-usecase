# **SkinBridge-Lite: Pipeline End-to-End de Preprocesamiento y Entrenamiento CNN desde Cero**

Este repositorio implementa un flujo de trabajo integral orientado al **an谩lisis, modelado y despliegue de un sistema de detecci贸n de melanomas mediante redes neuronales convolucionales (CNN)**.
El proyecto aborda todas las etapas del ciclo de vida de un modelo de machine learning aplicado a im谩genes m茅dicas: desde el preprocesamiento de datos y la definici贸n de arquitecturas, hasta la evaluaci贸n cuantitativa, la interpretabilidad y el despliegue operativo en un entorno contenedorizado.

El trabajo se desarroll贸 bajo la restricci贸n de **no emplear arquitecturas preentrenadas** (como ResNet, EfficientNet o DenseNet). Por tanto, se dise帽贸 una arquitectura CNN personalizada, optimizada para la naturaleza de los datos disponibles y para su ejecuci贸n eficiente en entornos con recursos limitados.

## **Estructura del proyecto**

La **presentaci贸n final del caso de uso** se encuentra disponible en:
[Presentaci贸n final del caso de uso: *Detecci贸n de Melanomas*](results/Caso01__Detecci贸n_Melanomas.pdf)

```bash
/config         Configuraciones globales y par谩metros de ejecuci贸n
/.cache         Datos crudos, preprocesados y resultados intermedios
/docs           Documentaci贸n t茅cnica y diagramas de arquitectura
/notebooks      Experimentaci贸n, validaci贸n visual y exploraci贸n
/results        M茅tricas, curvas de aprendizaje, reportes y presentaci贸n final
/src            C贸digo fuente (preprocesamiento, entrenamiento, m茅tricas)
/streamlit_app  C贸digo de la aplicaci贸n interactiva y componentes de interfaz
/tests          Pruebas unitarias y de rendimiento, incluyendo validaciones GPU
Dockerfile, .dockerignore, Makefile, pyproject.toml, requirements.txt
```

## **Arquitectura del modelo**

El modelo implementa una **red neuronal convolucional desarrollada desde cero**, con una estructura modular orientada a la clasificaci贸n binaria o multiclase.
La arquitectura est谩 compuesta por:

* Tres bloques convolucionales secuenciales con normalizaci贸n por lotes y funciones de activaci贸n ReLU.
* Capas de *pooling* y regularizaci贸n mediante *dropout*.
* Bloque final de *Global Average Pooling* seguido de una capa densa con activaci贸n *softmax*.
* Compatibilidad con entradas de tres o cuatro canales (RGB o RGB+H/S) seg煤n el preprocesamiento aplicado.

El dise帽o prioriza la interpretabilidad y la eficiencia. Se incorporaron t茅cnicas de visualizaci贸n de activaciones (Grad-CAM) para el an谩lisis cualitativo de resultados.

![Arquitectura CNN](docs/CNN_Architecture.png)`

## **Flujo de trabajo**

1. **Preprocesamiento de datos**
   * Limpieza de artefactos (vello, sombras, bordes).
   * Segmentaci贸n de lesiones y normalizaci贸n de intensidad.
   * Generaci贸n de canales crom谩ticos adicionales (RGB+H, RGB+S).
   * Augmentaciones geom茅tricas y crom谩ticas ligeras.

2. **Construcci贸n y entrenamiento del modelo**
   * Implementado en `train_run.py` con TensorFlow/Keras.
   * Entrenamiento supervisado con validaci贸n cruzada, control de tasa de aprendizaje y *early stopping*.
   * Registro de m茅tricas (p茅rdida, exactitud, AUC) y almacenamiento estructurado de resultados.

3. **Evaluaci贸n y an谩lisis**
   * Curvas ROC-AUC, matrices de confusi贸n y gr谩ficos de convergencia generados autom谩ticamente (`metrics.py`).
   * Exportaci贸n de resultados en formato JSON y gr谩ficos en `results/`.
   * Validaci贸n visual de gradientes y activaciones mediante Grad-CAM.

4. **Despliegue y operaci贸n**
   * Interfaz implementada en Streamlit para visualizaci贸n e inferencia.
   * Configuraci贸n de contenedores Docker para despliegue local o en la nube (Hugging Face Spaces).
   * Integraci贸n del modelo final alojado en Hugging Face Hub.

## **Entornos de ejecuci贸n**

El proyecto utiliza **dos entornos de trabajo diferenciados** con fines espec铆ficos:

1. **Entorno de desarrollo y entrenamiento (Poetry)**
   * Gestionado mediante `pyproject.toml` y `poetry.lock`.
   * Incluye dependencias para TensorFlow, PyTorch y bibliotecas auxiliares de entrenamiento.
   * Configurado para aprovechar aceleraci贸n por GPU mediante CUDA, permitiendo el reentrenamiento del modelo en entornos con soporte de hardware especializado.
   * En la carpeta `/tests` se incluyen scripts de validaci贸n que verifican la correcta detecci贸n y utilizaci贸n de la GPU.

2. **Entorno de despliegue de la aplicaci贸n (`requirements.txt`)**
   * Contiene 煤nicamente las dependencias necesarias para la ejecuci贸n de la interfaz Streamlit.
   * Permite construir una imagen Docker ligera y reproducible, separada del entorno de entrenamiento.
   * Facilita la portabilidad de la aplicaci贸n hacia entornos de inferencia (local o nube) sin incluir bibliotecas de alto peso computacional.

Esta separaci贸n garantiza reproducibilidad, control de versiones y optimizaci贸n de recursos entre las fases de desarrollo, experimentaci贸n y despliegue.

## **Instalaci贸n**

### **Entorno de desarrollo y entrenamiento**

```bash
# Crear el entorno gestionado con Poetry
poetry install

# Activar el entorno
poetry shell

# Verificar acceso a GPU: Tensorflow o PyTorch (opcional)
python tests/smoke_gpu_pt.py
python tests/smoke_gpu_ts.py
```

### **Entorno de despliegue de la aplicaci贸n**

```bash
# Crear entorno virtual ligero
python -m venv .venv
source .venv/bin/activate  # o .venv\Scripts\activate en Windows
pip install -r requirements.txt
```

#### **Ejecuci贸n de la aplicaci贸n local**

```bash
streamlit run streamlit_app/App.py
```

#### **Construcci贸n y despliegue con Docker**

```bash
docker build -t cancer-ai-app .
docker run -p 8501:8501 cancer-ai-app
```

## **Evaluaci贸n y resultados**

* M茅tricas de desempe帽o: p茅rdida, exactitud, ROC-AUC y matriz de confusi贸n.
* Resultados cuantitativos y gr谩ficos disponibles en el directorio `results/`.
* Registro autom谩tico de configuraci贸n, pesos del modelo y trazabilidad de cada ejecuci贸n.

[![Ver presentaci贸n](https://img.shields.io/badge/%20Abrir-Presentaci贸n%20Final-blue)](results/Caso01__Detecci贸n_Melanomas.pdf)

## **Licencia**

El proyecto se distribuye bajo la **licencia MIT**.
Consulte el archivo `LICENSE` para obtener los t茅rminos completos.
